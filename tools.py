# Functions for extracting info from scraped pages

import re

if __name__ == "__main__":
	print("I'm a library, silly!")
	exit()

def getCookie(res, name):
	"""
	requests response object
	name of cookie
	"""
	cookies = res.headers['Set-Cookie'].split(' ')
	for cookie in cookies:
		if cookie.startswith(name):
			return name + '=' + cookie[len(name)+1:-1] + ';'
	return None # not found :(

def getFormData(res, extra={}):
	"""
	requests response object
	[other stuff to add (like username or password)]
	"""
	page = res.text
	# form has id 'loginform'
	page = page[page.index('loginform'):]
	page = page[page.index('>')+1:page.index('</form')].replace('\n', '')
	inputs = [s for s in page.split('>') if 'value' in s]
	form = {}
	for i in inputs:
		nameI = i.index('name') + 6
		valueI = i.index('value') + 7
		name = i[nameI:].split('"')[0]
		value = i[valueI:].split('"')[0]
		form[name] = value
	for e in extra:
		form[e] = extra[e]
	return form

def getUserAgent():
	# so at some point this might actually make a random one but i cant be bothered right now sorry
	return 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Gecko/20100101 Firefox/69.0'
